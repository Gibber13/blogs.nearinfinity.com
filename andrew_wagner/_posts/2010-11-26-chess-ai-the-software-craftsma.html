---
atom_id: tag:www.nearinfinity.com,2010:/blogs//7.1794 # This is for backwards compatibility do not change!
permalink: /blogs/andrew_wagner/chess_ai_the_software_craftsma.html
layout: blogs
title: Chess AI, the software craftsmanship way
date: 2010-11-26 00:00:27 -05:00
---
There have been a number of recent blog entries lately about "clean code" and how clean is "too clean"[1]. This is a topic that I feel strongly about, especially since reading Bob Martin's book "Clean Code"[2] a few years ago.&nbsp;<div><br /></div><div>So I've decided to embark on a journey of seeing what it's like to really push myself to keep a very high level of quality of code on a project. Will it be fun, or annoying? Will the code really feel more readable by the end? What would it really be like to be 100% TDD and be able to refactor without fear?</div><div><br /></div><div>The project is an experimental chess AI. Where most such projects operate on a principle of generating as many positions as possible to look at, this one will "think" more in terms of plans and strategies.&nbsp;</div><div><br /></div><div>The codebase is in ruby, and here are the tools I've pulled together so far:</div><div><br /><div><ol><li>RSpec - I'm <a href="http://rspec.info/">using RSpec to specify the behavior of my code</a>. This gives me tremendous flexibility, and it's one of my favorite things about programming in ruby.</li><li>BDD/TDD - The classic&nbsp;<a href="http://www.pragprog.com/titles/achbd/the-rspec-book">RSpec book</a>&nbsp;talks about the process of going back and forth between acceptance tests and unit-level tests. I'm not going all the way to cucumber right now, but I am focusing on writing specs (using rspec) at both levels of abstraction.</li><li>Code coverage -&nbsp;<a href="https://github.com/colszowka/simplecov">I'm using the simplecov gem</a>&nbsp;to provide code coverage reports. I've hooked it up to rspec so that when I run my tests, it gives me a code coverage percentage right after the passed/pending/failed count, and also generates a more detailed HTML report if I need it.</li><li>Static analysis -&nbsp;<a href="https://github.com/kevinrutherford/reek/wiki/">Yet another great gem, called Reek.</a>&nbsp;This gem allows me to write a test which simply states that my code "should_not reek". A nice goal to strive for! If my code doesn't pass muster, my tests fail, and I'm forced to fix it before I move on. I've also hooked up&nbsp;<a href="http://ruby.sadi.st/Flog.html">flog</a>,&nbsp;<a href="http://ruby.sadi.st/Flay.html">flay</a>, and&nbsp;<a href="http://roodi.rubyforge.org/">roodi</a>, (<a href="http://blog.martyandrews.net/2009/05/enforcing-ruby-code-quality.html">this blog entry</a>&nbsp;was a big help in setting them all up). Of these, flog seems to work the best.</li></ol>So far, I certainly haven't produced anything ground-breaking. I'm pleased, however, with how the tools have come together to provide a cohesive strategy for improving the code incrementally.</div><div><br /></div><div>The strategy looks something like this:</div><div><ol><li>Write a high-level specification for a new feature.&nbsp;</li><li>Write a (failing) unit test that moves the codebase in the direction of passing the acceptance test.</li><li>Make the unit test pass.&nbsp;</li><li>Fix any static code analysis issues while keeping the unit tests passing</li><li>If the acceptance test from #1 is still failing, I return to number 2.</li></ol><div>One thing I discovered is that it's easy to get excited and write code to pass the feature-level tests while the unit-level tests are passing. To resist this temptation, I've set an additional goal that my unit tests provide 100% code coverage by themselves.</div><div><br /></div><div><a href="https://github.com/arwagner/rueno">Check out the results if you're interested</a>. So far, there's not a lot to it. The engine "solves" an extremely simple king and pawn "puzzle", where the right move is one of the few legal moves. Still, I think it's a nice framework to build on. And it's fun to be able to see output like this, anytime I want to know the health of my codebase:</div></div><div><br /></div><div><div>Finished in 1.15 seconds</div><div>35 examples, 0 failures</div><div>Coverage report generated for RSpec to C:/projects/ruby/rueno/coverage</div><div>100.0% coverage</div><div>flog analysis looks good at a threshold of 12!</div><div>flay analysis looks good at a threshold of 12!</div></div></div><div><br /></div><div>[1] Here's a sampling:&nbsp;<a href="http://myagileeducation.com/2010/need-we-always-write-clean-code/">http://myagileeducation.com/2010/need-we-always-write-clean-code/</a>&nbsp;,&nbsp;<a href="http://xprogramming.com/articles/how-do-we-choose/">http://xprogramming.com/articles/how-do-we-choose/</a>&nbsp;,&nbsp;<a href="http://xprogramming.com/articles/too-much-of-a-good-thing/">http://xprogramming.com/articles/too-much-of-a-good-thing/</a>&nbsp;,&nbsp;<a href="http://agile.dzone.com/news/three-rs-clean-code">http://agile.dzone.com/news/three-rs-clean-code</a></div><div><br /></div><div>[2]&nbsp;<a href="http://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882">http://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882</a>&nbsp;- every software developer should have to read it!</div> 
